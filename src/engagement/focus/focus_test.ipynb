{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@1640.025] global cap_gstreamer.cpp:1777 open OpenCV | GStreamer warning: Cannot query video position: status=0, value=-1, duration=-1\n",
      "libdc1394 error: Failed to initialize libdc1394\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not find the HAAR face detector location\n",
      "Reading the landmark detector/tracker from: /home/openface-build/build/bin/model/main_ceclm_general.txt\n",
      "Reading the landmark detector module from: /home/openface-build/build/bin/model/cen_general.txt\n",
      "Reading the PDM module from: /home/openface-build/build/bin/model/pdms/In-the-wild_aligned_PDM_68.txt....Done\n",
      "Reading the Triangulations module from: /home/openface-build/build/bin/model/tris_68.txt....Done\n",
      "Reading the intensity CEN patch experts from: /home/openface-build/build/bin/model/patch_experts/cen_patches_0.25_of.dat....Done\n",
      "Reading the intensity CEN patch experts from: /home/openface-build/build/bin/model/patch_experts/cen_patches_0.35_of.dat....Done\n",
      "Reading the intensity CEN patch experts from: /home/openface-build/build/bin/model/patch_experts/cen_patches_0.50_of.dat....Done\n",
      "Reading the intensity CEN patch experts from: /home/openface-build/build/bin/model/patch_experts/cen_patches_1.00_of.dat....Done\n",
      "Reading part based module....left_eye_28\n",
      "Reading the landmark detector/tracker from: /home/openface-build/build/bin/model/model_eye/main_clnf_synth_left.txt\n",
      "Reading the landmark detector module from: /home/openface-build/build/bin/model/model_eye/clnf_left_synth.txt\n",
      "Reading the PDM module from: /home/openface-build/build/bin/model/model_eye/pdms/pdm_28_l_eye_3D_closed.txt....Done\n",
      "Reading the intensity CCNF patch experts from: /home/openface-build/build/bin/model/model_eye/patch_experts/left_ccnf_patches_1.00_synth_lid_.txt....Done\n",
      "Reading the intensity CCNF patch experts from: /home/openface-build/build/bin/model/model_eye/patch_experts/left_ccnf_patches_1.50_synth_lid_.txt....Done\n",
      "Could not find the landmark detection model to load\n",
      "Done\n",
      "Reading part based module....right_eye_28\n",
      "Reading the landmark detector/tracker from: /home/openface-build/build/bin/model/model_eye/main_clnf_synth_right.txt\n",
      "Reading the landmark detector module from: /home/openface-build/build/bin/model/model_eye/clnf_right_synth.txt\n",
      "Reading the PDM module from: /home/openface-build/build/bin/model/model_eye/pdms/pdm_28_eye_3D_closed.txt....Done\n",
      "Reading the intensity CCNF patch experts from: /home/openface-build/build/bin/model/model_eye/patch_experts/ccnf_patches_1.00_synth_lid_.txt....Done\n",
      "Reading the intensity CCNF patch experts from: /home/openface-build/build/bin/model/model_eye/patch_experts/ccnf_patches_1.50_synth_lid_.txt....Done\n",
      "Could not find the landmark detection model to load\n",
      "Done\n",
      "Reading the landmark validation module....Done\n",
      "Reading the AU analysis module from: /home/openface-build/build/bin/AU_predictors/main_dynamic_svms.txt\n",
      "Reading the AU predictors from: /home/openface-build/build/bin/AU_predictors/AU_all_best.txt... Done\n",
      "Reading the PDM from: /home/openface-build/build/bin/AU_predictors/In-the-wild_aligned_PDM_68.txt... Done\n",
      "Reading the triangulation from:/home/openface-build/build/bin/AU_predictors/tris_68_full.txt... Done\n",
      "Attempting to read from file: calibrate.avi\n",
      "Device or file opened\n",
      "Starting tracking\n",
      "Reading the MTCNN face detector from: /home/openface-build/build/bin/model/mtcnn_detector/MTCNN_detector.txt\n",
      "Reading the PNet module from: /home/openface-build/build/bin/model/mtcnn_detector/PNet.dat\n",
      "Reading the RNet module from: /home/openface-build/build/bin/model/mtcnn_detector/RNet.dat\n",
      "Reading the ONet module from: /home/openface-build/build/bin/model/mtcnn_detector/ONet.dat\n",
      "0% 10% 20% 30% 40% 50% 60% 70% 80% 90% 100% \n",
      "Closing output recorder\n",
      "Closing input reader\n",
      "Closed successfully\n",
      "Postprocessing the Action Unit predictions\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "from focus_calibrator import * \n",
    "import cv2\n",
    "import datetime\n",
    "import os\n",
    "# Define the codec and create VideoWriter object\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "out = cv2.VideoWriter('calibrate.avi', fourcc, 20.0, (640, 480))\n",
    "\n",
    "# Open the default camera\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "        break\n",
    "    cv2.imshow('Video', frame)\n",
    "    # Write the flipped frame\n",
    "    out.write(frame)\n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('frame', frame)\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release everything if job is finished\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "os.system(\"docker exec openface_docker /home/openface-build/build/bin/FeatureExtraction -f calibrate.avi\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np \n",
    "from focus_calibrator import * \n",
    "os.system(\"docker exec openface_docker /home/openface-build/build/bin/FeatureExtraction -f demo.avi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from focus_calibrator import * \n",
    "gaze_tracker = Focus_Calibrator('processed/calibrate.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.42152466, 0.33183857, 0.40358744, 0.47533632, 0.4573991 ,\n",
       "       0.47533632, 0.015625  , 0.        , 0.078125  , 0.140625  ,\n",
       "       0.25      , 0.3125    , 0.65470852, 0.60089686, 0.57399103,\n",
       "       0.56502242, 0.58295964, 0.55605381, 0.55605381, 0.52017937,\n",
       "       0.48430493, 0.42152466, 0.43049327, 0.39461883, 0.33183857,\n",
       "       0.34080717, 0.33183857, 0.33183857, 0.34080717, 0.34977578,\n",
       "       0.35874439, 0.367713  , 0.367713  , 0.35874439, 0.367713  ,\n",
       "       0.367713  , 0.39461883, 0.39461883, 0.39461883, 0.42152466,\n",
       "       0.42152466, 0.43049327, 0.43946188, 0.46636771, 0.4573991 ,\n",
       "       0.4573991 , 0.44843049, 0.4573991 , 0.44843049, 0.4573991 ,\n",
       "       0.46636771, 0.46636771, 0.4573991 , 0.44843049, 0.44843049,\n",
       "       0.4573991 , 0.44843049, 0.4573991 , 0.44843049, 0.42152466,\n",
       "       0.32286996, 0.32286996, 0.32286996, 0.32286996, 0.30493274,\n",
       "       0.31390135, 0.29596413, 0.32286996, 0.33183857, 0.32286996,\n",
       "       0.34080717, 0.34080717, 0.32286996, 0.33183857, 0.33183857,\n",
       "       0.30493274, 0.32286996, 0.34080717, 0.35874439, 0.35874439,\n",
       "       0.33183857, 0.33183857, 0.33183857, 0.32286996, 0.31390135,\n",
       "       0.26008969, 0.24215247, 0.24215247, 0.25112108, 0.25112108,\n",
       "       0.25112108, 0.25112108, 0.26008969, 0.26008969, 0.26008969,\n",
       "       0.2690583 , 0.26008969, 0.25112108, 0.25112108, 0.26008969,\n",
       "       0.26008969, 0.26008969, 0.26008969, 0.24215247, 0.25112108,\n",
       "       0.24215247, 0.25112108, 0.25112108, 0.24215247, 0.24215247,\n",
       "       0.20627803, 0.1793722 , 0.14349776, 0.13452915, 0.18834081,\n",
       "       0.20627803, 0.18834081, 0.1793722 , 0.21524664, 0.26008969,\n",
       "       0.23318386, 0.19730942, 0.16143498, 0.12556054, 0.10762332,\n",
       "       0.02690583, 0.00896861, 0.        , 0.04484305, 0.05381166,\n",
       "       0.03587444, 0.01793722, 0.02690583, 0.03587444, 0.06278027,\n",
       "       0.07174888, 0.0896861 , 0.09865471, 0.11659193])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gaze_scores = gaze_tracker('processed/calibrate.csv')\n",
    "gaze_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@1717.387] global cap_gstreamer.cpp:1777 open OpenCV | GStreamer warning: Cannot query video position: status=0, value=-1, duration=-1\n",
      "libdc1394 error: Failed to initialize libdc1394\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not find the HAAR face detector location\n",
      "Reading the landmark detector/tracker from: /home/openface-build/build/bin/model/main_ceclm_general.txt\n",
      "Reading the landmark detector module from: /home/openface-build/build/bin/model/cen_general.txt\n",
      "Reading the PDM module from: /home/openface-build/build/bin/model/pdms/In-the-wild_aligned_PDM_68.txt....Done\n",
      "Reading the Triangulations module from: /home/openface-build/build/bin/model/tris_68.txt....Done\n",
      "Reading the intensity CEN patch experts from: /home/openface-build/build/bin/model/patch_experts/cen_patches_0.25_of.dat....Done\n",
      "Reading the intensity CEN patch experts from: /home/openface-build/build/bin/model/patch_experts/cen_patches_0.35_of.dat....Done\n",
      "Reading the intensity CEN patch experts from: /home/openface-build/build/bin/model/patch_experts/cen_patches_0.50_of.dat....Done\n",
      "Reading the intensity CEN patch experts from: /home/openface-build/build/bin/model/patch_experts/cen_patches_1.00_of.dat....Done\n",
      "Reading part based module....left_eye_28\n",
      "Reading the landmark detector/tracker from: /home/openface-build/build/bin/model/model_eye/main_clnf_synth_left.txt\n",
      "Reading the landmark detector module from: /home/openface-build/build/bin/model/model_eye/clnf_left_synth.txt\n",
      "Reading the PDM module from: /home/openface-build/build/bin/model/model_eye/pdms/pdm_28_l_eye_3D_closed.txt....Done\n",
      "Reading the intensity CCNF patch experts from: /home/openface-build/build/bin/model/model_eye/patch_experts/left_ccnf_patches_1.00_synth_lid_.txt....Done\n",
      "Reading the intensity CCNF patch experts from: /home/openface-build/build/bin/model/model_eye/patch_experts/left_ccnf_patches_1.50_synth_lid_.txt....Done\n",
      "Could not find the landmark detection model to load\n",
      "Done\n",
      "Reading part based module....right_eye_28\n",
      "Reading the landmark detector/tracker from: /home/openface-build/build/bin/model/model_eye/main_clnf_synth_right.txt\n",
      "Reading the landmark detector module from: /home/openface-build/build/bin/model/model_eye/clnf_right_synth.txt\n",
      "Reading the PDM module from: /home/openface-build/build/bin/model/model_eye/pdms/pdm_28_eye_3D_closed.txt....Done\n",
      "Reading the intensity CCNF patch experts from: /home/openface-build/build/bin/model/model_eye/patch_experts/ccnf_patches_1.00_synth_lid_.txt....Done\n",
      "Reading the intensity CCNF patch experts from: /home/openface-build/build/bin/model/model_eye/patch_experts/ccnf_patches_1.50_synth_lid_.txt....Done\n",
      "Could not find the landmark detection model to load\n",
      "Done\n",
      "Reading the landmark validation module....Done\n",
      "Reading the AU analysis module from: /home/openface-build/build/bin/AU_predictors/main_dynamic_svms.txt\n",
      "Reading the AU predictors from: /home/openface-build/build/bin/AU_predictors/AU_all_best.txt... Done\n",
      "Reading the PDM from: /home/openface-build/build/bin/AU_predictors/In-the-wild_aligned_PDM_68.txt... Done\n",
      "Reading the triangulation from:/home/openface-build/build/bin/AU_predictors/tris_68_full.txt... Done\n",
      "Attempting to read from file: test_vid.avi\n",
      "Device or file opened\n",
      "Starting tracking\n",
      "Reading the MTCNN face detector from: /home/openface-build/build/bin/model/mtcnn_detector/MTCNN_detector.txt\n",
      "Reading the PNet module from: /home/openface-build/build/bin/model/mtcnn_detector/PNet.dat\n",
      "Reading the RNet module from: /home/openface-build/build/bin/model/mtcnn_detector/RNet.dat\n",
      "Reading the ONet module from: /home/openface-build/build/bin/model/mtcnn_detector/ONet.dat\n",
      "0% 10% 20% 30% 40% 50% 60% 70% 80% 90% 100% \n",
      "Closing output recorder\n",
      "Closing input reader\n",
      "Closed successfully\n",
      "Postprocessing the Action Unit predictions\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "out = cv2.VideoWriter('test_vid.avi', fourcc, 20.0, (640, 480))\n",
    "\n",
    "# Open the default camera\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "        break\n",
    "    cv2.imshow('Video', frame)\n",
    "    # Write the flipped frame\n",
    "    out.write(frame)\n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('frame', frame)\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release everything if job is finished\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "os.system(\"docker exec openface_docker /home/openface-build/build/bin/FeatureExtraction -f test_vid.avi\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.031976264300874496"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gaze_scores = gaze_tracker('processed/test_vid.csv')\n",
    "np.min(gaze_scores)\n",
    "\n",
    "\n",
    "np.sum(gaze_scores < 0)/np.sum(gaze_scores > 0)\n",
    "np.var(gaze_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Can't receive frame (stream end?). Exiting ...\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "\n",
    "# Load gaze scores here, assuming gaze_scores is defined somewhere else\n",
    "# gaze_scores = ...\n",
    "\n",
    "# Initialize video capture\n",
    "cap = cv.VideoCapture('test_vid.avi')\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open video.\")\n",
    "    exit(1)\n",
    "\n",
    "frame_width = int(cap.get(3))\n",
    "frame_height = int(cap.get(4))\n",
    "size = (frame_width, frame_height)\n",
    "\n",
    "# Initialize VideoWriter\n",
    "result = cv.VideoWriter('output.avi', cv.VideoWriter_fourcc(*'XVID'), 10, size)\n",
    "\n",
    "index = 0\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "        break\n",
    "    \n",
    "    if index >= len(gaze_scores):\n",
    "        print(\"Index exceeds length of gaze scores.\")\n",
    "        break\n",
    "\n",
    "    # Adding gaze score to the frame\n",
    "    cv.putText(frame, \"Gaze Score: \" + str(gaze_scores[index]), (50, 50), cv.FONT_HERSHEY_DUPLEX, 0.9, (147, 58, 31), 1)\n",
    "    \n",
    "    # Show frame (for debugging, remove or comment out in production)\n",
    "    cv.imshow('frame', frame)\n",
    "    result.write(frame)\n",
    "    \n",
    "    index += 1\n",
    "    if cv.waitKey(33) == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "result.release()\n",
    "cv.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@733.124] global cap_gstreamer.cpp:1777 open OpenCV | GStreamer warning: Cannot query video position: status=0, value=-1, duration=-1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 28\u001b[0m\n\u001b[1;32m     23\u001b[0m result \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mVideoWriter(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfilename.avi\u001b[39m\u001b[38;5;124m'\u001b[39m,  \n\u001b[1;32m     24\u001b[0m                          cv2\u001b[38;5;241m.\u001b[39mVideoWriter_fourcc(\u001b[38;5;241m*\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMJPG\u001b[39m\u001b[38;5;124m'\u001b[39m), \n\u001b[1;32m     25\u001b[0m                          \u001b[38;5;241m10\u001b[39m, size) \n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m(\u001b[38;5;28;01mTrue\u001b[39;00m): \n\u001b[0;32m---> 28\u001b[0m     ret, frame \u001b[38;5;241m=\u001b[39m \u001b[43mvideo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m     30\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m:  \n\u001b[1;32m     31\u001b[0m   \n\u001b[1;32m     32\u001b[0m         \u001b[38;5;66;03m# Write the frame into the \u001b[39;00m\n\u001b[1;32m     33\u001b[0m         \u001b[38;5;66;03m# file 'filename.avi' \u001b[39;00m\n\u001b[1;32m     34\u001b[0m         result\u001b[38;5;241m.\u001b[39mwrite(frame) \n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import cv2 \n",
    "  \n",
    "   \n",
    "# Create an object to read  \n",
    "# from camera \n",
    "video = cv2.VideoCapture(0) \n",
    "   \n",
    "# We need to check if camera \n",
    "# is opened previously or not \n",
    "if (video.isOpened() == False):  \n",
    "    print(\"Error reading video file\") \n",
    "  \n",
    "# We need to set resolutions. \n",
    "# so, convert them from float to integer. \n",
    "frame_width = int(video.get(3)) \n",
    "frame_height = int(video.get(4)) \n",
    "   \n",
    "size = (frame_width, frame_height) \n",
    "   \n",
    "# Below VideoWriter object will create \n",
    "# a frame of above defined The output  \n",
    "# is stored in 'filename.avi' file. \n",
    "result = cv2.VideoWriter('filename.avi',  \n",
    "                         cv2.VideoWriter_fourcc(*'MJPG'), \n",
    "                         10, size) \n",
    "    \n",
    "while(True): \n",
    "    ret, frame = video.read() \n",
    "  \n",
    "    if ret == True:  \n",
    "  \n",
    "        # Write the frame into the \n",
    "        # file 'filename.avi' \n",
    "        result.write(frame) \n",
    "  \n",
    "        # Display the frame \n",
    "        # saved in the file \n",
    "        cv2.imshow('Frame', frame) \n",
    "  \n",
    "        # Press S on keyboard  \n",
    "        # to stop the process \n",
    "        if cv2.waitKey(1) & 0xFF == ord('s'): \n",
    "            break\n",
    "  \n",
    "    # Break the loop \n",
    "    else: \n",
    "        break\n",
    "  \n",
    "# When everything done, release  \n",
    "# the video capture and video  \n",
    "# write objects \n",
    "video.release() \n",
    "result.release() \n",
    "    \n",
    "# Closes all the frames \n",
    "cv2.destroyAllWindows() \n",
    "   \n",
    "print(\"The video was successfully saved\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
